{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "We will be using a collection of images of dogs, sorted by breed, as our dataset for this lab.  The dataset can be found at [footnote 1](#footnote1); it was created by Stanford graduate students and their advisor as a data set specifically for fine-grained image categorization. Besides the categorized pictures of dogs, the data set also includes bounding box annotations for each of the images, class labels, and information on how the creators used the set to train and test.  The full set contains 20,560 images, with 120 different breeds of dogs represented.  There are at least 148 images of each breed, with the Maltese dog having the most images at 252.  Each picture is at least 200 pixels by 200 pixels in size, with most pictures generally not being much larger than that.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "This data is a specifically created set of images, created using images found on ImageNet under the 'Canis familiaris' node.  The three graduate students, Khosla, Jayadevaprakash, and Yao, along with their mentor, Fei-Fei, created this set of images specifically with the purpose of creating a dataset for fine-grained image categorization.  They went through the images found on ImageNet one breed at a time, being sure to select images that were only classified under one node, and removed images which had distortion, major occlusion, and other defects, in order to create a subset of images that they believed addressed the drawbacks of other fine-grained image categorization datasets.  Further information about their process and their results in achieving their dataset goals can be found at [footnote 2](#footnote2).\n",
    "\n",
    "### Prediction Task\n",
    "\n",
    "The prediction task for this dataset is relatively simple: to be able to recognize the breed of a dog from a picture, which may be of different age, color, shape than the original images, or which may be partially occluded. Generally, there is little inter-class variation in the appearance of dogs <sup>[[1]](#footnote1)</sup> and large intra-class variation<sup>[[1]](#footnote1)</sup>, making recognizing dogs a tough challenge for categorization.  Even with a human, there are certain types of dogs that pose challenges when it comes to differentiation, especially among mixed breed dogs; to be able to identify the type of dog in an image mechanically would help in cases as simple as a person trying to identify what breeds are in a mongrel's ancestry. <br><br>\n",
    "At a more advanced level, it would be helpful to many photo sharing websites to be able to recognize a type of dog from the image posted, in order to create more tailored advertising for said person.  To be able to recognize a dog is to be able to advertise generalized dog products at a user, while to be able to recognize breed is to be able to target a user for very specific dog-related purchases, which may drive higher advertising revenue.  It has been demonstrated how much more effective targeted ads can be than their non-targeted counterparts<sup>[[3]](#footnote3)</sup>; to continue to truly personalize ads based on the very specifics of a person's lifestyle is the ultimate goal of web advertisment. Advertising is what drives the modern web, and the modern dog owner spends \\$1549<sup>[[4]](#footnote4)</sup> per year on dog-related purchases, to be able to further target advertising has the potential to be very valuable. <br><br>\n",
    "Besides helping those mentioned above, the ability to identify dogs is one that has major implications to veterinarians and others in industries working directly with dogs.  When it comes to caring for dogs, there are material differences between certain breeds. Different breeds vary in their needs, including requiring different nutrition<sup>[[5]](#footnote5)</sup> and different levels of exercise<sup>[[6]](#footnote6)</sup>; most important, however, is dosage of veterinary drugs. There are certain drugs used by vets that are important to the health of a dog, but have the potential to be deadly to certain breeds which carry specific gene mutations<sup>[[7]](#footnote7)</sup>.  To be able to identify a dog, and avoid using a drug that could have fatal side effects is invaluable.  With a mechanical method of dog identification, vets can be more certain that they are treating a dog the correct way for its genetics, and are advising the owners of the correct way to feed and take care of it on a regular basis. <br><br>\n",
    "Another field in which being able to identify a dog is important is pet adoption and animal shelters. One in ten dogs adopted from shelters in the United States are returned within six months, most often due to unexpected costs or behaviors<sup>[[8]](#footnote8)</sup>.  Many adopt dogs not knowing the dog's exact genetic makeup, and are unaware of what the dog will grow into from the puppy they adopt.  While it is impossible to fully predict a dog's size and behavior simply from its ancestry, the ancestry is still one of the best indicators of what a dog will be like as an adult.  To be able to tell what kind of dog a puppy will become can assist in the operations of pet shelters and other adoption organiztions, giving them the ability to inform the customer what they can expect in the future from any given dog. <br><br>\n",
    "Finally, it can be important to identify dogs in order to know that one is receiving the actual type of dog that they are told they are receiving.  Only two states currently offer statutory recourse for the misrepresentation of a breed in purchasing a dog: Florida and Minnesota<sup>[[9]](#footnote9)</sup>. In other states, it is possible to attempt recourse through various other methods, such as breach of contract, but it is not always guaranteed that the customer can be assured that they will receive exactly what they wanted.  With a method of identifying dogs that does not rely on human trust, customers can feel more confident in their purchases of dogs, knowing that they are almost certainly purchasing the correct merchandise.\n",
    "\n",
    "### Third Parties\n",
    "\n",
    "The third parties that would be interested in such a classification system would be a combination of social media sites and advertisers.  Working in unison, they would be able to look at the pictures posted on the social media account of a user, and not only determine what kind of pet they have, they could go further and determine the subtype of that pet, in order to maximize personalization of the ads.  The most obvious example of a site that would use a system such as this one would be Instagram. Instagram is entirely based around lifestyle and images, and pet photos are very common. In the past, Instagram has been cited as a model that may have a difficult time monetizing, so to be able to further increase the probability of someone clicking on an advertisment is very valuable.  Similar rationales exist with Facebook, Twitter, even Snapchat (albeit somewhat ethically fuzzier with Snap).  Overall, any site that relies on user-generated content and advertising would likely reap the benefits of being able to classify pets as granularly as possible. <br><br>\n",
    "Besides the third parties in technology, anyone in the fields of veterinary medicine and dog breeding, or even just those that love dogs, could use the app to help in the pursuit of those things.  Whether it is ensuring that the medicine being given is appropriate, confirming that a dog is what it is being said, or just trying to identify a cute dog seen in one's neighborhood, the ability to identify or confirm the human identification of a dog is a valuable resource.  In the United States, 36.5% of households own dogs<sup>[[10]](#footnote10)</sup>; it is the largest pet market in the country.  From owning dogs, to selling dogs, to treating dogs, the identification of dogs runs through American life; lending a helping hand through technology could touch millions of lives, helping both the humans and their dogs.\n",
    "\n",
    "### Cited\n",
    "<a name=\"footnote1\">1</a>: http://vision.stanford.edu/aditya86/ImageNetDogs/ <br>\n",
    "<a name=\"footnote2\">2</a>: http://people.csail.mit.edu/khosla/papers/fgvc2011.pdf <br>\n",
    "<a name=\"footnote3\">3</a>: https://hbr.org/2016/04/targeted-ads-dont-just-make-you-more-likely-to-buy-they-can-change-how-you-think-about-yourself <br>\n",
    "<a name=\"footnote4\">4</a>: http://www.americanpetproducts.org/press_industrytrends.asp <br>\n",
    "<a name=\"footnote5\">5</a>: https://www.petmd.com/blogs/nutritionnuggets/jcoates/2012/feb/nutrition_differences_for_small_toy_large_breeds-12459 <br>\n",
    "<a name=\"footnote6\">6</a>: https://thebark.com/content/how-much-exercise-does-your-dog-need <br>\n",
    "<a name=\"footnote7\">7</a>: https://www.petmd.com/blogs/fullyvetted/2013/jan/toxic-ivermectin-and-safe-use-of-ivermectin-29671 <br>\n",
    "<a name=\"footnote8\">8</a>: https://www.americanhumane.org/app/uploads/2016/08/petsmart-keeping-pets-phase-ii.pdf <br>\n",
    "<a name=\"footnote9\">9</a>: https://www.avma.org/Advocacy/StateAndLocal/Pages/pet-lemon-laws.aspx <br>\n",
    "<a name=\"footnote10\">10</a>: https://www.avma.org/KB/Resources/Statistics/Pages/Market-research-statistics-US-pet-ownership.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "#Get rid of memory cached by jupyter notebook\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "\n",
    "#Set the image size and path to the data\n",
    "img_size = (300,400)\n",
    "img_path = 'Images/'\n",
    "img_paths = []\n",
    "img_annotations = []\n",
    "\n",
    "#The images are stored in subdirectories - go through all of them\n",
    "for dirpath, dirnames, filenames in os.walk(img_path):\n",
    "    for filename in [f for f in filenames if f.endswith(\".jpg\")]:\n",
    "        img_paths.append(os.path.join(dirpath, filename))\n",
    "        img_annotations.append(dirpath.split('/')[1].split('-')[1])\n",
    "\n",
    "print(img_paths[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_data = []\n",
    "for path in img_paths[0:1000]:\n",
    "    img_data.append(color.rgb2grey(resize(plt.imread(path).astype(np.uint8),img_size)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4665d45e3fe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    plt.imshow(img_data[random.randint(0,len(img_data))].reshape(img_size),cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import corner_harris, corner_subpix, corner_peaks\n",
    "from skimage.transform import warp, AffineTransform\n",
    "\n",
    "\n",
    "tform = AffineTransform(scale=(1.3, 1.1), rotation=1, shear=0.7,\n",
    "                        translation=(210, 50))\n",
    "image = warp(data.checkerboard(), tform.inverse, output_shape=(350, 350))\n",
    "image = img_data[random.randint(0,len(img_data))].reshape(img_size)\n",
    "coords = corner_peaks(corner_harris(image), min_distance=5)\n",
    "coords_subpix = corner_subpix(image, coords, window_size=13)\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(image, interpolation='nearest')\n",
    "plt.plot(coords_subpix[:, 1], coords_subpix[:, 0], '+r', markersize=15, mew=5)\n",
    "plt.plot(coords[:, 1], coords[:, 0], '.b', markersize=7)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
